# Guide

In this chapter, we will cover some of the concepts and technologies that are
used during the course. We will introduce the following topics:

## Apache Spark

A framework for processing large amounts of data on multiple machines in a
robust way. We will build our application for labs 1 and 2 using Spark.

## Amazon Web Services

AWS, which provide theoretically unlimited compute infrastructure, allowing us
to process a dataset as large as the entire GDELT database in lab 2.

## Apache Kafka

A framework for building so-called data pipelines, in which potentially many
producers and consumers process real-time, streaming data. In lab 3, we will
take the application from labs 1 and 2 and modify it to process data in
real-time, using Kafka.

## Scala

A programming language that runs on the Java Virtual Machine (JVM). This is our
(mandatory!) language of choice during the lab assignments. We will use it to
program for both Apache Spark and Apache Kafka.

## Docker

An application that allows the user to package and run software (like Spark and
Kafka and the programs we write for them) in an isolated environment: a
container.

## OpenStreetMap

A open source project capturing geographic data from all over the world. The
assignments of this lab are based on (parts of) this data set.
